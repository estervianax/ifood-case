# Targeted Tastes, an iFood Case Study ğŸ›µğŸ”

This project delivers actionable insights into customer behavior and offer effectiveness by identifying the best offer to send to each customer, aiming to maximize conversion rates through data-driven strategies.

It preprocesses raw data and explores historical trends to create a unified dataset that combines information about offers, transactions, and customer profiles.  
This enables the development of a predictive model capable of estimating the probability that a given customer will complete an offer they receive.

Key technologies used include:
- **Apache Spark** for large-scale data processing.
- **LightGBM** for building machine learning model.
- **Scikit-learn** for additional model evaluation and utilities.

Final outputs include:
- A clean, structured dataset ready for modeling.
- Visualizations to support analysis and reporting.
- A trained model prepared for deployment.

## Project Structure

ifood_case/  
â”œâ”€â”€ notebooks/  
â”‚   â”œâ”€â”€ 1_data_preprocessing.ipynb      
â”‚   â””â”€â”€ 2_modeling.ipynb                 
â”‚  
â”œâ”€â”€ presentation/                        
â”‚  
â”œâ”€â”€ src/                                 
â”‚   â”œâ”€â”€ __init__.py  
â”‚   â”œâ”€â”€ data_preprocessing.py            
â”‚   â”œâ”€â”€ historical_data_viz.py  
â”‚   â”œâ”€â”€ impact_evaluate.py          
â”‚   â”œâ”€â”€ model_evaluate.py                
â”‚   â””â”€â”€ model_train.py                   
â”‚  
â”œâ”€â”€ data/  
â”‚   â”œâ”€â”€ raw/                             
â”‚   â”‚   â”œâ”€â”€ profile.json  
â”‚   â”‚   â”œâ”€â”€ transactions.json  
â”‚   â”‚   â””â”€â”€ offers.json  
â”‚   â”‚  
â”‚   â””â”€â”€ processed/                       
â”‚       â”œâ”€â”€ df_model.parquet  
â”‚       â””â”€â”€ df_all.parquet  
â”‚  
â”œâ”€â”€ __init__.py  
â”œâ”€â”€ .gitignore                           
â”œâ”€â”€ setup.py                             
â”œâ”€â”€ requirements.txt                     
â””â”€â”€ README.md                           

## Installation

1. Clone repository:
    ```bash
    git clone https://github.com/yourusername/poultryhealthpredict.git
    cd poultryhealthpredict
    ```

2. Create virtual environment and activate it:
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3. Install required packages:
    ```bash
    pip install -r requirements.txt
    ```
4. Install directory as package in editable mode:
    ```bash
    pip install -e .
    ```

## Usage

The project is divided into two main steps, each handled by a separate notebook:

### 1. Data Preprocessing
- **Notebook**: `1_data_preprocessing.ipynb`
- **Technologies**: Apache Spark and Pandas
- **Description**:
  - Clean, preprocess, and prepare the dataset for modeling.
  - Use **Spark** for scalable data operations.
  - Perform **exploratory data analysis (EDA)** using **Pandas** for easy visualization and insights.

### 2. Modeling
- **Notebook**: `2_modeling.ipynb`
- **Technology**: Pandas
- **Description**:
  - Train and evaluate machine learning models (LightGBM).
  - Perform hyperparameter tuning using `RandomizedSearchCV`.
  - Visualize feature importance, confusion matrix, and assess model performance.

---

## Code Overview

| File                     | Description |
|---------------------------|-------------|
| `data_preprocessing.py`   | Cleans, filters, and merges data from the raw sources to create a model-ready dataset. |
| `historical_data_viz.py`  | Generates visualizations to explore customer behavior, offer success, and transaction history. |
| `model_evaluate.py`       | Evaluates model predictions with detailed metrics and visualizations (classification report, confusion matrix). |
| `model_train.py`          | Trains and tunes LightGBM models using a full pipeline (preprocessing + model). |
| `impact_evaluate.py`      | Calculation reference for model's impact, to be used for informational purposes only. |


